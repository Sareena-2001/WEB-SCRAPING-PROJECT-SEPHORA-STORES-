# -*- coding: utf-8 -*-
"""file.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T3ebYGWoHyhQBrxspF5la6TmD-fil-6m
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd

def extract_store_details(store_elem):
    store_details = {
        'web_scraper_order': store_elem.get('web_scraper_order', 'missing'),
        'web-scraper-start-url': store_elem.get('web-scraper-url', 'missing'),
        'location_title': store_elem.get('loc_title', 'missing'),
        'city': store_elem.get('store_city', 'missing'),
        'location_of_store-irvine': store_elem.get('store-irvine', 'missing'),
        'location_of_store-sandiego': store_elem.get('store-sandiego', 'missing'),
        'location-losangeles': store_elem.get('losangeles', 'missing'),
        'country': store_elem.get('store_country', 'missing'),
        'phone': store_elem.get('store_phone', 'missing'),
        'hoursofoperation': store_elem.get('op_hours', 'missing'),
        'latitude': store_elem.get('lat', 'missing'),
        'longitude':store_elem.get('long', 'missing'),
    }
    return store_details

def scrape_sephora_stores(url):
    response = requests.get(url)
    response.raise_for_status()  # Check for request errors
    soup = BeautifulSoup(response.text, 'html.parser')

    stores = []

    # Update selector based on actual HTML structure
    store_elements = soup.find_all('div', class_='store-item')  # Example class name

    for store_elem in store_elements:
        web_scraper_order = store_elem.find('h3', class_='web-scraper-ord')
        web_scraper_start_url = store_elem.find('p', class_='web_scraper_url')
        location_title= store_elem.find('span', class_='loc_title')
        city= store_elem.find('span', class_='store_city')
        location_of_store_irvine = store_elem.find('span', class_='store_irvine')
        location_of_store_sandiego = store_elem.find('div', class_='store_sandiego')
        location_losangeles= store_elem.find('div', class_='store_la')
        country = store_elem.get('countr', 'N/A')
        phone = store_elem.find('div', class_='store_phone')
        hoursofoperation = store_elem.find('div', class_='hrsofop')
        allstores = store_elem.find('div', class_='store_all')
        latitude = store_elem.find('div', class_='lat')
        longitude = store_elem.find('div', class_='long')


        store = {
            'web_scraper_order': web_scraper_order.text if web_scraper_order else 'N/A',
            ' web_scraper_start_url':  web_scraper_start_url.text if  web_scraper_start_url else 'N/A',
            ' location_title':   location_title.text if   location_title else 'N/A',
            ' city': city.text if city else 'N/A',
            'country': 'USA',
            'location_of_store_irvine': location_of_store_irvine.text if location_of_store_irvine else 'N/A',
            'location_of_store_sandiego': location_of_store_sandiego.text if location_of_store_sandiego else 'N/A',
            'location_losangeles': location_losangeles.text if location_losangeles else 'N/A',
            'phone': phone.text if phone else 'N/A',
            'hoursofoperation' : hoursofoperation.number if hoursofoperation else 'N/A',
            'allstores': allstores.text if allstores else 'N/A',
            'latitude':   latitude.text if   latitude else 'N/A',
            'longitude':  longitude.text if  longitude else 'N/A'

        }

        if store['State'] == 'CA':
            stores.append(store)

    return stores

url = 'https://www.sephora.com/happening/storelist'
store_data = scrape_sephora_stores(url)

# Save data to CSV
df = pd.DataFrame(store_data)
df.to_csv('sephora_california_stores.csv')